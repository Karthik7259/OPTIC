<div align="center">

# ğŸ¤– OPTIC - FastAPI Services
### AI-Powered Backend Services & Task Management

[![FastAPI](https://img.shields.io/badge/FastAPI-0.115.12-green.svg)](https://fastapi.tiangolo.com/)
[![Flask](https://img.shields.io/badge/Flask-3.1.0-blue.svg)](https://flask.palletsprojects.com/)
[![Python](https://img.shields.io/badge/Python-3.8+-yellow.svg)](https://python.org/)
[![Langchain](https://img.shields.io/badge/Langchain-Community-purple.svg)](https://langchain.com/)
[![Ollama](https://img.shields.io/badge/Ollama-LLM-orange.svg)](https://ollama.ai/)

*AI-driven employee task assignment and HR analytics powered by Large Language Models*

</div>

---

## ğŸ“– Table of Contents

- [ğŸš€ Overview](#-overview)
- [âœ¨ Features](#-features)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸ› ï¸ Technology Stack](#ï¸-technology-stack)
- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ”§ API Endpoints](#-api-endpoints)
- [ğŸ¤– AI Models](#-ai-models)
- [ğŸ”§ Configuration](#-configuration)
- [ğŸ“Š Employee Management](#-employee-management)
- [ğŸ§ª Development](#-development)
- [ğŸ“¦ Deployment](#-deployment)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“ Support](#-support)

---

## ğŸš€ Overview

The AURA AI FastAPI Services provide intelligent task assignment and HR analytics capabilities powered by Large Language Models (LLMs). This service uses both **Ollama** for local LLM inference and **Groq** for cloud-based AI processing to optimize employee task allocation and provide intelligent workforce management.

### ğŸ¯ Key Capabilities

- ğŸ¤– **Intelligent Task Assignment** - AI-powered employee matching based on skills and availability
- ğŸ‘¥ **HR Analytics** - Workforce optimization and performance insights
- ğŸ“Š **Real-time Employee Management** - Dynamic task allocation and tracking
- ğŸ” **Skill-based Matching** - Advanced algorithms for optimal task-employee pairing
- âš¡ **High Performance** - FastAPI and Flask hybrid architecture for optimal performance

---

## âœ¨ Features

### ğŸ¯ **AI-Powered Task Assignment**
- **Smart Employee Matching**: Analyzes skills, experience, and productivity
- **Dynamic Load Balancing**: Distributes tasks based on current workload
- **Availability Tracking**: Real-time employee availability management
- **Performance Optimization**: Considers past performance for future assignments

### ğŸ“Š **HR Analytics & Insights**
- **Workforce Analytics**: Employee productivity and task completion analysis
- **Skill Gap Analysis**: Identifies training needs and skill development areas
- **Performance Metrics**: Tracks individual and team productivity metrics
- **Resource Optimization**: Optimal resource allocation recommendations

### ğŸ”§ **Intelligent Automation**
- **Automated Task Distribution**: AI-driven task assignment workflows
- **Priority-based Assignment**: Handles urgent tasks with intelligent prioritization
- **Conflict Resolution**: Manages scheduling conflicts and resource constraints
- **Predictive Analytics**: Forecasts project completion and resource needs

---

## ğŸ—ï¸ Architecture

<div align="center">

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AI SERVICES LAYER                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ¤– Task Assignment API    â”‚  ğŸ‘¥ HR Analytics API           â”‚
â”‚  (Flask + Ollama LLama3)   â”‚  (Flask + Groq LLama3)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    LLM PROCESSING LAYER                    â”‚
â”‚  ğŸ§  Ollama (Local)         â”‚  â˜ï¸ Groq (Cloud)              â”‚
â”‚  - Task Analysis           â”‚  - HR Insights                â”‚
â”‚  - Employee Matching       â”‚  - Performance Analytics      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    DATA PROCESSING LAYER                   â”‚
â”‚  ğŸ“Š Employee Database      â”‚  ğŸ“ˆ Analytics Engine          â”‚
â”‚  - Skills & Experience     â”‚  - Performance Metrics        â”‚
â”‚  - Availability Status     â”‚  - Task Completion History    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

</div>

---

## ğŸ“ Project Structure

```
ğŸ“¦ fastapi/
â”œâ”€â”€ ğŸ“„ api.py                    # Main task assignment API
â”œâ”€â”€ ğŸ“„ hr.py                     # HR analytics and management API
â”œâ”€â”€ ğŸ“„ requirements.txt          # Python dependencies
â””â”€â”€ ğŸ“„ README.md                 # This documentation

ğŸ“Š Data Models:
â”œâ”€â”€ ğŸ‘¤ Employee Model
â”‚   â”œâ”€â”€ name: str
â”‚   â”œâ”€â”€ skills: List[str]
â”‚   â”œâ”€â”€ experience: int
â”‚   â”œâ”€â”€ productivity: float
â”‚   â”œâ”€â”€ occupied: bool
â”‚   â”œâ”€â”€ current_task: str
â”‚   â””â”€â”€ tasks_completed: int
â”‚
â””â”€â”€ ğŸ“‹ Task Request Model
    â””â”€â”€ description: str
```

---

## ğŸ› ï¸ Technology Stack

### ğŸ **Core Framework**
| Technology | Version | Purpose |
|------------|---------|---------|
| **FastAPI** | 0.115.12 | High-performance async API framework |
| **Flask** | 3.1.0 | Lightweight web framework for specific endpoints |
| **Python** | 3.8+ | Core programming language |
| **Uvicorn** | 0.34.2 | ASGI server for FastAPI |

### ğŸ¤– **AI & Machine Learning**
| Technology | Version | Purpose |
|------------|---------|---------|
| **Langchain Community** | Latest | LLM integration and prompt management |
| **Ollama** | Latest | Local LLM inference (LLama3) |
| **Groq** | 0.23.0 | Cloud-based LLM processing |
| **Phidata** | 2.7.10 | AI assistant framework |

### ğŸ”§ **Utilities & Integration**
| Technology | Version | Purpose |
|------------|---------|---------|
| **Pydantic** | 2.11.3 | Data validation and serialization |
| **CORS** | Latest | Cross-origin resource sharing |
| **python-dotenv** | 1.1.0 | Environment variable management |
| **Rich** | 14.0.0 | Beautiful terminal output |

---

## ğŸš€ Quick Start

### ğŸ“‹ Prerequisites
- ğŸ Python 3.8 or higher
- ğŸ¦™ Ollama installed locally (for LLama3 model)
- ğŸ”‘ Groq API key (for cloud AI services)
- ğŸ“¦ pip package manager

### âš¡ Installation

1. **ğŸ“¥ Navigate to FastAPI Directory**
   ```bash
   cd path/to/optic/fastapi
   ```

2. **ğŸ”§ Create Virtual Environment**
   ```bash
   python -m venv venv
   
   # Windows
   venv\Scripts\activate
   
   # macOS/Linux
   source venv/bin/activate
   ```

3. **ğŸ“¦ Install Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **ğŸ”‘ Environment Setup**
   ```bash
   # Create .env file
   echo "GROQ_API_KEY=your_groq_api_key_here" > .env
   ```

5. **ğŸ¦™ Setup Ollama**
   ```bash
   # Install Ollama (if not already installed)
   # Download from: https://ollama.ai/
   
   # Pull LLama3 model
   ollama pull llama3
   ```

### ğŸš€ Running the Services

#### ğŸ¤– **Task Assignment API** (Port: 8000)
```bash
python api.py
```

#### ğŸ‘¥ **HR Analytics API** (Port: 5000)
```bash
python hr.py
```

#### âš¡ **Using Uvicorn (Alternative)**
```bash
# For FastAPI applications
uvicorn api:app --host 0.0.0.0 --port 8000 --reload
```

---

## ğŸ”§ API Endpoints

### ğŸ¤– **Task Assignment API** (`api.py`)

#### **POST /evaluate-task/**
Evaluates task description and recommends best employees based on AI analysis.

**Request:**
```json
{
  "description": "Develop a React frontend with authentication and user dashboard"
}
```

**Response:**
```json
{
  "task": "Develop a React frontend with authentication and user dashboard",
  "recommendations": "1. Alice: Expert in React, Node.js, MongoDB with 3 years experience and 8.5/10 productivity\n2. Frank: Strong backend skills with Go, Kubernetes, Docker, 7 years experience and 9.7/10 productivity\n3. [Third recommendation]"
}
```

**Features:**
- ğŸ¯ AI-powered skill matching
- ğŸ“Š Experience and productivity analysis
- ğŸ§  LLama3 model reasoning
- âš¡ Real-time task evaluation

### ğŸ‘¥ **HR Analytics API** (`hr.py`)

#### **POST /assign-task**
Assigns tasks to employees based on availability and workload optimization.

**Employee Database:**
```csv
name,occupied,current_task,tasks_completed
Alice,Yes,Build Authentication Module,12
Bob,No,API Backend for Task Management,20
Charlie,Yes,Dashboard UI for Analytics,8
David,Yes,Cloud Deployment Automation,30
Eve,Yes,Microservices Integration,17
```

**Assignment Logic:**
1. ğŸŸ¢ **Priority 1**: Assign to free employees
2. ğŸŸ¡ **Priority 2**: If all busy, assign to employee with fewer completed tasks
3. ğŸ”„ **Load Balancing**: Optimal workload distribution

---

## ğŸ¤– AI Models

### ğŸ¦™ **Ollama LLama3** (Local Processing)
- **Usage**: Task evaluation and employee matching
- **Benefits**: 
  - ğŸ”’ Privacy-focused (local processing)
  - âš¡ Low latency for frequent requests
  - ğŸ’° No API costs
- **Model**: `llama3`
- **Requirements**: Local Ollama installation

### â˜ï¸ **Groq LLama3** (Cloud Processing)
- **Usage**: HR analytics and complex reasoning
- **Benefits**:
  - ğŸš€ High performance cloud processing
  - ğŸ“ˆ Advanced analytical capabilities
  - ğŸ”„ Scalable for heavy workloads
- **Model**: `llama3-8b-8192`
- **Requirements**: Groq API key

---

## ğŸ”§ Configuration

### ğŸŒ **Environment Variables**

Create a `.env` file in the fastapi directory:

```env
# Groq API Configuration
GROQ_API_KEY=your_groq_api_key_here

# Optional: Custom model configurations
OLLAMA_MODEL=llama3
GROQ_MODEL=llama3-8b-8192

# Optional: Server configurations
API_HOST=0.0.0.0
API_PORT=8000
HR_PORT=5000
```

### âš™ï¸ **API Configuration**

**CORS Settings:**
```python
# Task Assignment API
CORS(app, origins=["http://localhost:5177"], supports_credentials=True)

# HR Analytics API
CORS(app, origins=["http://localhost:5177"], supports_credentials=True)
```

### ğŸ¦™ **Ollama Setup**

1. **Install Ollama**
   ```bash
   # Visit: https://ollama.ai/download
   # Or use package manager
   ```

2. **Pull Required Models**
   ```bash
   ollama pull llama3
   ```

3. **Verify Installation**
   ```bash
   ollama list
   ```

---

## ğŸ“Š Employee Management

### ğŸ‘¤ **Employee Data Model**

```python
class Employee(BaseModel):
    name: str                    # Employee name
    skills: List[str]           # Technical skills
    experience: int             # Years of experience
    productivity: float         # Productivity score (0-10)
    occupied: bool              # Current availability status
    current_task: str           # Current assignment
    tasks_completed: int        # Total completed tasks
```

### ğŸ“ˆ **Sample Employee Database**

```python
employees = [
    Employee(
        name="Alice", 
        skills=["React", "Node.js", "MongoDB"], 
        experience=3, 
        productivity=8.5,
        occupied=True,
        current_task="Build Authentication Module",
        tasks_completed=12
    ),
    Employee(
        name="Frank", 
        skills=["Go", "Kubernetes", "Docker"], 
        experience=7, 
        productivity=9.7,
        occupied=False,
        current_task="",
        tasks_completed=20
    )
    # ... more employees
]
```

### ğŸ¯ **Assignment Algorithm**

1. **Skill Matching**: Analyzes required skills vs employee expertise
2. **Experience Weighting**: Considers years of experience for complex tasks
3. **Productivity Scoring**: Factors in historical performance metrics
4. **Availability Check**: Prioritizes available employees
5. **Load Balancing**: Distributes workload evenly across team

---

## ğŸ§ª Development

### ğŸ”§ **Development Workflow**

1. **ğŸš€ Start Development Servers**
   ```bash
   # Terminal 1: Task Assignment API
   python api.py
   
   # Terminal 2: HR Analytics API  
   python hr.py
   ```

2. **ğŸ§ª Test API Endpoints**
   ```bash
   # Test task assignment
   curl -X POST http://localhost:8000/evaluate-task/ \
     -H "Content-Type: application/json" \
     -d '{"description": "Build a React dashboard"}'
   
   # Test HR assignment
   curl -X POST http://localhost:5000/assign-task \
     -H "Content-Type: application/json" \
     -d '{"task": "Frontend development"}'
   ```

3. **ğŸ“Š Monitor Ollama**
   ```bash
   # Check Ollama status
   ollama ps
   
   # View Ollama logs
   ollama logs
   ```

### ğŸ” **Debugging**

**Common Issues:**

<details>
<summary>ğŸ¦™ Ollama Connection Issues</summary>

```bash
# Check if Ollama is running
ollama ps

# Restart Ollama
ollama serve

# Verify model availability
ollama list
```
</details>

<details>
<summary>ğŸ”‘ Groq API Key Issues</summary>

```bash
# Check environment variables
echo $GROQ_API_KEY

# Verify .env file
cat .env

# Test API key
curl -H "Authorization: Bearer $GROQ_API_KEY" https://api.groq.com/openai/v1/models
```
</details>

<details>
<summary>ğŸŒ CORS Issues</summary>

```python
# Update CORS origins in api.py and hr.py
CORS(app, origins=["http://localhost:3000", "http://localhost:5177"])
```
</details>

### ğŸ“ **Adding New Features**

1. **New AI Models**
   ```python
   # Add new model in api.py
   from langchain_community.llms import AnotherLLM
   
   new_llm = AnotherLLM(model="model-name")
   ```

2. **Custom Employee Attributes**
   ```python
   # Extend Employee model
   class Employee(BaseModel):
       # ... existing fields
       department: str
       manager: str
       availability_hours: List[int]
   ```

3. **Advanced Analytics**
   ```python
   # Add new analytics endpoints in hr.py
   @app.route("/analytics/performance", methods=["GET"])
   def get_performance_analytics():
       # Implementation
   ```

---

## ğŸ“¦ Deployment

### ğŸ³ **Docker Deployment**

Create `Dockerfile`:
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install Ollama
RUN curl -fsSL https://ollama.ai/install.sh | sh

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

# Pull Ollama model
RUN ollama pull llama3

EXPOSE 8000 5000

CMD ["python", "api.py"]
```

### â˜ï¸ **Cloud Deployment**

**Environment Setup:**
```bash
# Production environment variables
export GROQ_API_KEY=prod_groq_key
export OLLAMA_HOST=ollama.yourdomain.com
export API_HOST=0.0.0.0
export API_PORT=8000
```

**Process Management:**
```bash
# Using gunicorn for production
pip install gunicorn

# Run API service
gunicorn -w 4 -k uvicorn.workers.UvicornWorker api:app --bind 0.0.0.0:8000

# Run HR service
gunicorn -w 4 hr:app --bind 0.0.0.0:5000
```

---

## ğŸ¤ Contributing

### ğŸ“ **Contribution Guidelines**

1. **ğŸ´ Fork the repository**
2. **ğŸŒ¿ Create a feature branch**
   ```bash
   git checkout -b feature/ai-enhancement
   ```
3. **ğŸ’¾ Make your changes**
   - Follow PEP 8 style guidelines
   - Add proper documentation
   - Include error handling
4. **ğŸ§ª Test your changes**
   ```bash
   python -m pytest tests/
   ```
5. **ğŸ“¤ Submit a pull request**

### ğŸ”§ **Development Setup**
```bash
# Clone and setup
git clone <repository-url>
cd fastapi
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
pip install -r requirements.txt
```

### ğŸ§ª **Testing**
```bash
# Install testing dependencies
pip install pytest pytest-asyncio httpx

# Run tests
pytest tests/ -v

# Run with coverage
pytest --cov=. tests/
```

---

## ğŸ“ Support

### ğŸ†˜ **Getting Help**

- ğŸ“§ **Email**: ai-support@auraai.com
- ğŸ› **Issues**: [Report AI service issues](../../issues)
- ğŸ“š **Documentation**: Check API documentation and inline docs
- ğŸ’¬ **Community**: Join our AI developer community

### ğŸ”§ **Performance Optimization**

- ğŸ¦™ **Ollama Optimization**: Use GPU acceleration if available
- â˜ï¸ **Groq Rate Limits**: Implement proper rate limiting
- ğŸ“Š **Caching**: Cache frequent AI responses
- âš¡ **Async Processing**: Use async/await for better performance

---

<div align="center">

# ğŸ¤– AI Services

**Part of the AURA AI OPTIC Platform**

*Powered by LLama3, Langchain, and modern AI technologies*

---

### ğŸŒŸ Intelligent Task Assignment & HR Analytics

[![API Status](https://img.shields.io/badge/API-Online-green)](http://localhost:8000)
[![AI Models](https://img.shields.io/badge/AI-LLama3-blue)](https://ollama.ai/)
[![Performance](https://img.shields.io/badge/Performance-Optimized-orange)](../../)

</div>
